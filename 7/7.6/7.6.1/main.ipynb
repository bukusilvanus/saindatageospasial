{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "data.dropna(subset=['Survived'], inplace=True)\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "data = pd.get_dummies(data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "X = data.drop('Survived', axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 1s 2ms/step - loss: 0.6519 - accuracy: 0.6685\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7767\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7851\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7978\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7992\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8048\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8244\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8244\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8258\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f82e02cf880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 38s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 16:17:15.531489: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 19s 12ms/step - loss: 1.5106 - accuracy: 0.4597\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2075 - accuracy: 0.5751\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 1.0914 - accuracy: 0.6185\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.9992 - accuracy: 0.6524\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.9390 - accuracy: 0.6733\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0639 - accuracy: 0.6321\n",
      "Test Loss: 1.0639, Test Accuracy: 0.6321\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('ndvi.csv')\n",
    "ndvi_values = data['value'].values.reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(ndvi_values)\n",
    "timesteps = 10\n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - timesteps):\n",
    "    X.append(data_scaled[i:i + timesteps, 0])\n",
    "    y.append(data_scaled[i + timesteps, 0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.0132\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.0132\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.0132\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.0132\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.0132\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.0132\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6768 - accuracy: 0.0132\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6764 - accuracy: 0.0132\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6755 - accuracy: 0.0132\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6747 - accuracy: 0.0132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f827c687250>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    SimpleRNN(64, activation='relu',\n",
    "    input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bukusilvanus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
